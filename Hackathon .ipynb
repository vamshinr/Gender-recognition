{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vamsh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vamsh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vamsh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vamsh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(init=\"uniform\",activation=\"relu\",output_dim=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vamsh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=5, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(init=\"uniform\",activation=\"sigmoid\",output_dim=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vamsh\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vamsh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vamsh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\Hackathon\\\\gender'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3bf62ab8c7a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                                  \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                  \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                                                      class_mode = 'categorical')\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    538\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m         )\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\Hackathon\\\\gender'"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'D:\\Hackathon\\gender',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                     class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'asian': 0, 'black': 1, 'indian': 2, 'other': 3, 'white': 4}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 109 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test = test_datagen.flow_from_directory(r'D:\\Hackathon\\test-gender',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 62s 246ms/step - loss: 0.4300 - acc: 0.8000 - val_loss: 0.5658 - val_acc: 0.8000\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.4268 - acc: 0.8000 - val_loss: 0.5685 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 0.4299 - acc: 0.8000 - val_loss: 0.5656 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.4297 - acc: 0.8000 - val_loss: 0.5659 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 59s 238ms/step - loss: 0.4264 - acc: 0.8000 - val_loss: 0.5717 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.4314 - acc: 0.8000 - val_loss: 0.5631 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.4265 - acc: 0.8000 - val_loss: 0.5706 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 0.4301 - acc: 0.8000 - val_loss: 0.5672 - val_acc: 0.8000\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 61s 242ms/step - loss: 0.4301 - acc: 0.8000 - val_loss: 0.5631 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.4300 - acc: 0.8000 - val_loss: 0.5633 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.4257 - acc: 0.8000 - val_loss: 0.5709 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 59s 238ms/step - loss: 0.4313 - acc: 0.8000 - val_loss: 0.5660 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 59s 238ms/step - loss: 0.4267 - acc: 0.8000 - val_loss: 0.5679 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.4310 - acc: 0.8000 - val_loss: 0.5675 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.4249 - acc: 0.8000 - val_loss: 0.5709 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 60s 238ms/step - loss: 0.4304 - acc: 0.8000 - val_loss: 0.5645 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 59s 238ms/step - loss: 0.4312 - acc: 0.8000 - val_loss: 0.5655 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 60s 240ms/step - loss: 0.4279 - acc: 0.8000 - val_loss: 0.5662 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.4278 - acc: 0.8000 - val_loss: 0.5663 - val_acc: 0.8000\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.4301 - acc: 0.8000 - val_loss: 0.5648 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.4280 - acc: 0.8000 - val_loss: 0.5676 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 60s 240ms/step - loss: 0.4272 - acc: 0.8000 - val_loss: 0.5670 - val_acc: 0.8000 4s - loss\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.4303 - acc: 0.8000 - val_loss: 0.5673 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.4281 - acc: 0.8000 - val_loss: 0.5688 - val_acc: 0.8000\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 58s 234ms/step - loss: 0.4285 - acc: 0.8000 - val_loss: 0.5683 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.4286 - acc: 0.8000 - val_loss: 0.5683 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.4303 - acc: 0.8000 - val_loss: 0.5651 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.4268 - acc: 0.8000 - val_loss: 0.5706 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.4292 - acc: 0.8000 - val_loss: 0.5671 - val_acc: 0.8000\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 57s 230ms/step - loss: 0.4295 - acc: 0.8000 - val_loss: 0.5668 - val_acc: 0.8000\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 62s 247ms/step - loss: 0.4284 - acc: 0.8000 - val_loss: 0.5665 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.4306 - acc: 0.8000 - val_loss: 0.5674 - val_acc: 0.8000\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 58s 231ms/step - loss: 0.4278 - acc: 0.8000 - val_loss: 0.5669 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 60s 240ms/step - loss: 0.4277 - acc: 0.8000 - val_loss: 0.5572 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.4274 - acc: 0.8000 - val_loss: 0.5666 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.4255 - acc: 0.8000 - val_loss: 0.5649 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 57s 229ms/step - loss: 0.4254 - acc: 0.8000 - val_loss: 0.5608 - val_acc: 0.8000\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.4281 - acc: 0.8000 - val_loss: 0.5592 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.4247 - acc: 0.8013 - val_loss: 0.5663 - val_acc: 0.7831\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.4172 - acc: 0.8257 - val_loss: 0.5637 - val_acc: 0.7944\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.4269 - acc: 0.8105 - val_loss: 0.5558 - val_acc: 0.8000\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.4237 - acc: 0.8200 - val_loss: 0.5578 - val_acc: 0.7965\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.4214 - acc: 0.8254 - val_loss: 0.5610 - val_acc: 0.7967\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 61s 242ms/step - loss: 0.4175 - acc: 0.8300 - val_loss: 0.5619 - val_acc: 0.7870\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.4185 - acc: 0.8291 - val_loss: 0.5680 - val_acc: 0.7759\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.4178 - acc: 0.8293 - val_loss: 0.5591 - val_acc: 0.7832\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.4161 - acc: 0.8308 - val_loss: 0.5654 - val_acc: 0.7786\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.4131 - acc: 0.8319 - val_loss: 0.5500 - val_acc: 0.7946\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 61s 242ms/step - loss: 0.4110 - acc: 0.8329 - val_loss: 0.5610 - val_acc: 0.7816\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.4102 - acc: 0.8334 - val_loss: 0.5682 - val_acc: 0.7756\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.4102 - acc: 0.8333 - val_loss: 0.5686 - val_acc: 0.7708\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.4073 - acc: 0.8340 - val_loss: 0.5600 - val_acc: 0.7801\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.4026 - acc: 0.8366 - val_loss: 0.5591 - val_acc: 0.7775024 -\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.4013 - acc: 0.8358 - val_loss: 0.5447 - val_acc: 0.7892\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 0.4036 - acc: 0.8333 - val_loss: 0.5624 - val_acc: 0.7768\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.3995 - acc: 0.8358 - val_loss: 0.5329 - val_acc: 0.7999\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.3982 - acc: 0.8363 - val_loss: 0.5520 - val_acc: 0.7857\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 60s 240ms/step - loss: 0.3950 - acc: 0.8385 - val_loss: 0.5630 - val_acc: 0.7784ss:\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 61s 242ms/step - loss: 0.3922 - acc: 0.8387 - val_loss: 0.5418 - val_acc: 0.7990\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.3946 - acc: 0.8386 - val_loss: 0.5509 - val_acc: 0.7852\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.3893 - acc: 0.8389 - val_loss: 0.5441 - val_acc: 0.7886\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 61s 245ms/step - loss: 0.3845 - acc: 0.8420 - val_loss: 0.5430 - val_acc: 0.8000\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 56s 223ms/step - loss: 0.3889 - acc: 0.8399 - val_loss: 0.5372 - val_acc: 0.7948\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.3831 - acc: 0.8428 - val_loss: 0.5538 - val_acc: 0.7852\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.3840 - acc: 0.8420 - val_loss: 0.5299 - val_acc: 0.8023\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.3785 - acc: 0.8450 - val_loss: 0.5254 - val_acc: 0.7962\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.3794 - acc: 0.8444 - val_loss: 0.5484 - val_acc: 0.7938\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.3747 - acc: 0.8459 - val_loss: 0.5429 - val_acc: 0.7967\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 59s 238ms/step - loss: 0.3720 - acc: 0.8480 - val_loss: 0.5338 - val_acc: 0.8017\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 57s 228ms/step - loss: 0.3694 - acc: 0.8484 - val_loss: 0.5309 - val_acc: 0.8036\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 0.3712 - acc: 0.8477 - val_loss: 0.5401 - val_acc: 0.7963\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 59s 238ms/step - loss: 0.3676 - acc: 0.8493 - val_loss: 0.5542 - val_acc: 0.7925\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.3650 - acc: 0.8510 - val_loss: 0.5559 - val_acc: 0.7849\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 58s 231ms/step - loss: 0.3633 - acc: 0.8519 - val_loss: 0.5461 - val_acc: 0.7997\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 60s 242ms/step - loss: 0.3617 - acc: 0.8521 - val_loss: 0.5429 - val_acc: 0.7953\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 58s 234ms/step - loss: 0.3622 - acc: 0.8505 - val_loss: 0.5400 - val_acc: 0.7943\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.3584 - acc: 0.8538 - val_loss: 0.5367 - val_acc: 0.7975\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.3583 - acc: 0.8528 - val_loss: 0.5443 - val_acc: 0.7995\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.3551 - acc: 0.8545 - val_loss: 0.5327 - val_acc: 0.7968\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.3531 - acc: 0.8552 - val_loss: 0.5270 - val_acc: 0.8040\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.3497 - acc: 0.8570 - val_loss: 0.5442 - val_acc: 0.7956\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 0.3522 - acc: 0.8557 - val_loss: 0.5329 - val_acc: 0.8021\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 62s 247ms/step - loss: 0.3430 - acc: 0.8610 - val_loss: 0.5587 - val_acc: 0.7934\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.3452 - acc: 0.8612 - val_loss: 0.5620 - val_acc: 0.7851\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 56s 224ms/step - loss: 0.3461 - acc: 0.8582 - val_loss: 0.5321 - val_acc: 0.7944\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 62s 247ms/step - loss: 0.3423 - acc: 0.8611 - val_loss: 0.5558 - val_acc: 0.7748\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.3423 - acc: 0.8636 - val_loss: 0.5552 - val_acc: 0.7807\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 59s 238ms/step - loss: 0.3360 - acc: 0.8667 - val_loss: 0.5275 - val_acc: 0.7893\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.3357 - acc: 0.8656 - val_loss: 0.5434 - val_acc: 0.7782\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.3402 - acc: 0.8642 - val_loss: 0.5261 - val_acc: 0.7865\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 58s 234ms/step - loss: 0.3340 - acc: 0.8679 - val_loss: 0.5534 - val_acc: 0.7747\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.3334 - acc: 0.8675 - val_loss: 0.5532 - val_acc: 0.7873\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 0.3325 - acc: 0.8682 - val_loss: 0.5625 - val_acc: 0.7766\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.3287 - acc: 0.8703 - val_loss: 0.5480 - val_acc: 0.7820\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 0.3301 - acc: 0.8686 - val_loss: 0.5449 - val_acc: 0.7797\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 0.3261 - acc: 0.8720 - val_loss: 0.5750 - val_acc: 0.7779\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 58s 234ms/step - loss: 0.3268 - acc: 0.8693 - val_loss: 0.5632 - val_acc: 0.7756\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.3254 - acc: 0.8721 - val_loss: 0.5637 - val_acc: 0.7831\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 0.3247 - acc: 0.8718 - val_loss: 0.5624 - val_acc: 0.7733\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 0.3196 - acc: 0.8746 - val_loss: 0.5922 - val_acc: 0.7638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a7344b7d68>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,\n",
    "                         steps_per_epoch = 250,\n",
    "                         epochs = 100,\n",
    "                         validation_data = x_test,\n",
    "                         validation_steps = 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "+###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "def detect(frame):\n",
    "    try:\n",
    "        img=resize(frame,(64,64))\n",
    "        img=np.expand_dims(img,axis=0)\n",
    "        if(np.max(img)>1):\n",
    "            img=img/255\n",
    "        prediction=model.predict(img)\n",
    "        print(prediction)\n",
    "        prediction_class=model.predict_classes(img)\n",
    "        #print(prediction_class)\n",
    "        return prediction_class.item(0)\n",
    "    except AttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A:\\ANACONDA_INSTALLED\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14635563 0.05764501 0.3060608  0.09820214 0.2651399 ]]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(r\"D:\\Hackathon\\test-race\\white\\1_0_0_20161219191041403.jpg\")\n",
    "n=detect(frame)\n",
    "cv2.imshow(str(n),frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"final-gen.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
